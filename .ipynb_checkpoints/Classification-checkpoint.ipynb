{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9ae198",
   "metadata": {
    "id": "af9ae198"
   },
   "outputs": [],
   "source": [
    "import os          \n",
    "import cv2\n",
    "import netron\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot\n",
    "from datetime import datetime      \n",
    "import matplotlib.pyplot as plt \n",
    "from ann_visualizer.visualize import ann_viz\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn.model_selection as model_selection\n",
    "\n",
    "%load_ext tensorboard\n",
    "logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a494a18",
   "metadata": {
    "id": "5a494a18"
   },
   "outputs": [],
   "source": [
    "def load_data(dataset):\n",
    "    class_names = []\n",
    "    images = []\n",
    "    labels = []  \n",
    "    for folder in os.listdir(dataset):\n",
    "        class_names.append(folder)    \n",
    "    class_names_label = {class_name:i for i, class_name in enumerate(class_names)} \n",
    "    print(\"Loading Dataset {}\".format(dataset))\n",
    "    for folder in os.listdir(dataset):\n",
    "        label = class_names_label[folder]\n",
    "        for file in tqdm(os.listdir(os.path.join(dataset, folder))):\n",
    "            img_path = os.path.join(os.path.join(dataset, folder), file)\n",
    "            image = cv2.imread(img_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            IMAGE_SIZE = (150, 150)\n",
    "            image = cv2.resize(image, IMAGE_SIZE)\n",
    "            images.append(image)\n",
    "            labels.append(label)\n",
    "    return images, labels , class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c672c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = '/home/ragu/DATASETS/TEMP/'\n",
    "images, labels, class_names = load_data(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658435ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array(images, dtype = 'float32')\n",
    "labels = np.array(labels, dtype = 'int32') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9030843",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb0fe3c",
   "metadata": {
    "id": "8eb0fe3c"
   },
   "outputs": [],
   "source": [
    "train_images, test_images, train_labels, test_labels = model_selection.train_test_split(images, labels, train_size=0.80,test_size=0.20, random_state=101) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79291a4",
   "metadata": {
    "id": "d79291a4",
    "outputId": "e35a7c47-4bbc-490e-e3a6-b35365bb80ec"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu', input_shape = (150, 150, 3)), \n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(30, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add8c701",
   "metadata": {
    "id": "add8c701"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3a11b6",
   "metadata": {
    "id": "ac3a11b6",
    "outputId": "34bcdf90-1da0-4da5-ad11-d36f54024a70"
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_images, train_labels, batch_size=128, epochs = 50, validation_split = 0.2,callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d015843e",
   "metadata": {
    "id": "d015843e",
    "outputId": "bdc0d61a-5807-4295-e2f7-282d3a27c95d"
   },
   "outputs": [],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7c9f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_loss(history):\n",
    "    y = ['accuracy','loss']\n",
    "    for x in y:\n",
    "        plt.plot(history.history[x],color='orange', label = x )\n",
    "        plt.plot(history.history['val_'+x], color='lime', label ='val_'+x)\n",
    "        plt.title(\"train_\"+x + \" vs val_\"+x)\n",
    "        plt.ylabel(x)\n",
    "        plt.xlabel(\"epochs\")\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0604a789",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af37f22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measures(y_actual, y_pred):\n",
    "    \n",
    "    confusion_matrix_df = pd.DataFrame(confusion_matrix(actual,predictions),index = class_names, columns =class_names)\n",
    "\n",
    "    FP = confusion_matrix_df.sum(axis=0) - np.diag(confusion_matrix_df) \n",
    "    FN = confusion_matrix_df.sum(axis=1) - np.diag(confusion_matrix_df)\n",
    "    TP = np.diag(confusion_matrix_df)\n",
    "    TN = confusion_matrix_df.sum() - (FP + FN + TP)\n",
    "    NPV = TN/(TN+FN)\n",
    "    FDR = FP/(TP+FP)\n",
    "    FNR = FP/(FP+TN)\n",
    "    Accuracy = (TP + TN) / (TP + FP + FN + TN)\n",
    "    Error_rate = (FP + FN) / (TP + FP + FN + TN)\n",
    "    Precision = TP / (TP + FP)\n",
    "    Recall = TP / (TP + FN )\n",
    "    F_measure = (2 * Recall * Precision) / (Recall + Precision)\n",
    "    Fall_out = FN/(TP+FN)\n",
    "    Specificity = TN/(TN+FP)\n",
    "    \n",
    "    dict = {}\n",
    "    dict['class_name'] = class_names\n",
    "    dict['TP'] = TP\n",
    "    dict['FP'] = FP\n",
    "    dict['TN'] = TN\n",
    "    dict['FN'] = FN\n",
    "    dict['NPV'] = NPV\n",
    "    dict['FDR'] = FDR\n",
    "    dict['FNR'] = FNR\n",
    "    dict['Accuracy'] = Accuracy\n",
    "    dict['Error_rate'] = Error_rate\n",
    "    dict['Precision'] = Precision\n",
    "    dict['Recall'] = Recall\n",
    "    dict['F_measure'] = F_measure\n",
    "    dict['Fall_out'] = Fall_out\n",
    "    dict['Specificity'] = Specificity\n",
    "    \n",
    "    measures = pd.DataFrame(dict)\n",
    "\n",
    "    plt.figure(figsize=(15,15))\n",
    "    sns.heatmap(confusion_matrix_df, annot=True)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('Actal Values')\n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.show()\n",
    "    print(measures)\n",
    "    \n",
    "predictions = np.argmax(model.predict(test_images), axis = 1)\n",
    "actual = test_labels\n",
    "measures(actual, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf7f973",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b84fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualkeras\n",
    "visualkeras.layered_view(model, legend=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d335ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_img_file = 'model.png'\n",
    "tf.keras.utils.plot_model(model, to_file=dot_img_file, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50ff077",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_base_dir = \"./logs\"\n",
    "os.makedirs(logs_base_dir, exist_ok=True)\n",
    "%tensorboard --logdir {logs_base_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9e29b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_viz(model, title=\"RRNET8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9a2bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'RRNET8.h5'\n",
    "model.save(model_name)\n",
    "netron.start(model_name, 8081)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efdb2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    \n",
    "    if 'conv' not in layer.name:\n",
    "        continue    \n",
    "    filters , bias = layer.get_weights()\n",
    "    print(layer.name , filters.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f1c3cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2ed0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.get_layer(\"conv2d\").get_weights()[1]\n",
    "plt.figure(figsize=(15,7))\n",
    "sns.barplot(x=np.arange(len(weights)), y=weights)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8c4cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = model.get_layer(\"dense\").get_weights()[1]\n",
    "plt.figure(figsize=(15,7))\n",
    "sns.barplot(x=np.arange(len(bias)), y=bias)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6e3cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.get_layer('dense_1').get_weights()[0]\n",
    "sns.distplot(weights)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4969f709",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_maps = tf.keras.models.Model(model.input, model.get_layer('conv2d').output)\n",
    "feature_maps.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff29efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters , bias = model.layers[1].get_weights()\n",
    "f_min, f_max = filters.min(), filters.max()\n",
    "filters = (filters - f_min) / (f_max - f_min)\n",
    "n_filters =6\n",
    "ix=1\n",
    "fig = pyplot.figure(figsize=(20,15))\n",
    "for i in range(n_filters):\n",
    "    \n",
    "    f = filters[:,:,:,i]\n",
    "    for j in range(3):\n",
    "       \n",
    "        pyplot.subplot(n_filters,3,ix)\n",
    "        pyplot.imshow(f[:,:,j] ,cmap='gray')\n",
    "        ix+=1\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ab5ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "blocks = [ ] \n",
    "for i in range(len(model.layers)):\n",
    "    layer = model.layers[i]\n",
    "    if 'conv' not in layer.name:\n",
    "        continue    \n",
    "    print(i , layer.name , layer.output.shape)\n",
    "    blocks.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c769d546",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = [model.layers[i].output for i in blocks]\n",
    "\n",
    "model = tf.keras.models.Model( inputs= model.inputs, outputs = outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5f392f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "  from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.utils import  img_to_array \n",
    "from matplotlib import pyplot\n",
    "from numpy import expand_dims\n",
    "\n",
    "model = VGG16()\n",
    "\n",
    "model = Model(inputs=model.inputs, outputs=model.layers[1].output)\n",
    "model.summary()\n",
    "\n",
    "img = load_img('bird.jpg', target_size=(224, 224))\n",
    "\n",
    "img = img_to_array(img)\n",
    "\n",
    "img = expand_dims(img, axis=0)\n",
    "\n",
    "img = preprocess_input(img)\n",
    "\n",
    "feature_maps = model.predict(img)\n",
    "\n",
    "square = 8\n",
    "ix = 1\n",
    "for _ in range(square):\n",
    "\n",
    " ax = pyplot.subplot(square, square, ix)\n",
    " ax.set_xticks([])\n",
    " ax.set_yticks([])\n",
    "\n",
    " pyplot.imshow(feature_maps[0, :, :, ix-1], cmap='gray')\n",
    " ix += 1\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e478a739",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://data.world/datasets/dna"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
