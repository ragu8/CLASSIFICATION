{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af9ae198",
   "metadata": {
    "id": "af9ae198"
   },
   "outputs": [],
   "source": [
    "import os          \n",
    "import cv2                                 \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import *         \n",
    "import matplotlib.pyplot as plt \n",
    "import sklearn.model_selection as model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a494a18",
   "metadata": {
    "id": "5a494a18"
   },
   "outputs": [],
   "source": [
    "def load_data(dataset):\n",
    "    class_names = []\n",
    "    images = []\n",
    "    labels = []  \n",
    "    for folder in os.listdir(dataset):\n",
    "        class_names.append(folder)    \n",
    "    class_names_label = {class_name:i for i, class_name in enumerate(class_names)} \n",
    "    print(\"Loading Dataset {}\".format(dataset))\n",
    "    for folder in os.listdir(dataset):\n",
    "        label = class_names_label[folder]\n",
    "        for file in tqdm(os.listdir(os.path.join(dataset, folder))):\n",
    "            img_path = os.path.join(os.path.join(dataset, folder), file)\n",
    "            image = cv2.imread(img_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            IMAGE_SIZE = (150, 150)\n",
    "            image = cv2.resize(image, IMAGE_SIZE)\n",
    "            images.append(image)\n",
    "            labels.append(label)\n",
    "    return images, labels , class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05c672c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Dataset ../dataset/mist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 60/60 [00:00<00:00, 5538.01it/s]\n",
      "100%|█████████████████████████████████████████| 60/60 [00:00<00:00, 5359.33it/s]\n",
      "100%|█████████████████████████████████████████| 60/60 [00:00<00:00, 3783.99it/s]\n",
      "100%|█████████████████████████████████████████| 60/60 [00:00<00:00, 4360.36it/s]\n",
      "100%|█████████████████████████████████████████| 60/60 [00:00<00:00, 3549.18it/s]\n",
      "100%|███████████████████████████████████████| 189/189 [00:00<00:00, 6036.26it/s]\n",
      "100%|█████████████████████████████████████████| 60/60 [00:00<00:00, 8835.07it/s]\n",
      "100%|█████████████████████████████████████████| 60/60 [00:00<00:00, 8720.57it/s]\n",
      "100%|█████████████████████████████████████████| 60/60 [00:00<00:00, 6922.63it/s]\n",
      "100%|█████████████████████████████████████████| 60/60 [00:00<00:00, 6859.42it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = '../dataset/mist'\n",
    "images, labels, class_names = load_data(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "658435ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array(images, dtype = 'float32')\n",
    "labels = np.array(labels, dtype = 'int32') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9030843",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8eb0fe3c",
   "metadata": {
    "id": "8eb0fe3c"
   },
   "outputs": [],
   "source": [
    "train_images, test_images, train_labels, test_labels = model_selection.train_test_split(images, labels, train_size=0.80,test_size=0.20, random_state=101) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d79291a4",
   "metadata": {
    "id": "d79291a4",
    "outputId": "e35a7c47-4bbc-490e-e3a6-b35365bb80ec"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (150, 150, 3)), \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(30, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "add8c701",
   "metadata": {
    "id": "add8c701"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_accuracy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac3a11b6",
   "metadata": {
    "id": "ac3a11b6",
    "outputId": "34bcdf90-1da0-4da5-ad11-d36f54024a70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-05 10:28:43.576921: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 125820000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/ragu/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/ragu/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/ragu/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/ragu/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 809, in train_step\n        loss = self.compiled_loss(\n    File \"/home/ragu/anaconda3/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 184, in __call__\n        self.build(y_pred)\n    File \"/home/ragu/anaconda3/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 133, in build\n        self._losses = tf.nest.map_structure(self._get_loss_object, self._losses)\n    File \"/home/ragu/anaconda3/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 273, in _get_loss_object\n        loss = losses_mod.get(loss)\n    File \"/home/ragu/anaconda3/lib/python3.9/site-packages/keras/losses.py\", line 2134, in get\n        return deserialize(identifier)\n    File \"/home/ragu/anaconda3/lib/python3.9/site-packages/keras/losses.py\", line 2089, in deserialize\n        return deserialize_keras_object(\n    File \"/home/ragu/anaconda3/lib/python3.9/site-packages/keras/utils/generic_utils.py\", line 708, in deserialize_keras_object\n        raise ValueError(\n\n    ValueError: Unknown loss function: sparse_categorical_accuracy. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8054/1172267578.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/ragu/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/ragu/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/ragu/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/ragu/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 809, in train_step\n        loss = self.compiled_loss(\n    File \"/home/ragu/anaconda3/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 184, in __call__\n        self.build(y_pred)\n    File \"/home/ragu/anaconda3/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 133, in build\n        self._losses = tf.nest.map_structure(self._get_loss_object, self._losses)\n    File \"/home/ragu/anaconda3/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 273, in _get_loss_object\n        loss = losses_mod.get(loss)\n    File \"/home/ragu/anaconda3/lib/python3.9/site-packages/keras/losses.py\", line 2134, in get\n        return deserialize(identifier)\n    File \"/home/ragu/anaconda3/lib/python3.9/site-packages/keras/losses.py\", line 2089, in deserialize\n        return deserialize_keras_object(\n    File \"/home/ragu/anaconda3/lib/python3.9/site-packages/keras/utils/generic_utils.py\", line 708, in deserialize_keras_object\n        raise ValueError(\n\n    ValueError: Unknown loss function: sparse_categorical_accuracy. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images, train_labels, batch_size=128, epochs=10, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2890a1a",
   "metadata": {
    "id": "d2890a1a"
   },
   "outputs": [],
   "source": [
    "def plot_accuracy_loss(history):\n",
    "    y = ['accuracy','loss']\n",
    "    for x in y:\n",
    "        plt.plot(history.history[x],'bo--', label = x )\n",
    "        plt.plot(history.history['val_'+x], 'ro--', label ='val_'+x)\n",
    "        plt.title(\"train_\"+x + \" vs val_\"+x)\n",
    "        plt.ylabel(x)\n",
    "        plt.xlabel(\"epochs\")\n",
    "        plt.legend()\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889e0f49",
   "metadata": {
    "id": "889e0f49",
    "outputId": "33dbc4e9-8b28-42db-95d4-d7919731d729"
   },
   "outputs": [],
   "source": [
    "plot_accuracy_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d015843e",
   "metadata": {
    "id": "d015843e",
    "outputId": "bdc0d61a-5807-4295-e2f7-282d3a27c95d"
   },
   "outputs": [],
   "source": [
    "test_loss = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea40239",
   "metadata": {
    "id": "2ea40239",
    "outputId": "9b6581d4-5364-44dc-b9df-cf84277d1204"
   },
   "outputs": [],
   "source": [
    "predictions = np.argmax(model.predict(test_images), axis = 1)\n",
    "actual = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a710b8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_df = pd.DataFrame(confusion_matrix(actual,predictions),index = class_names, columns =class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d266825d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "sns.heatmap(confusion_matrix_df, annot=True)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actal Values')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd049cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
